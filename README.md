# ğŸ¤– ENEM Data Robotics V2

![Python](https://img.shields.io/badge/Python-3.12%2B-blue?style=for-the-badge&logo=python)
![React](https://img.shields.io/badge/React-18-61DAFB?style=for-the-badge&logo=react)
![TypeScript](https://img.shields.io/badge/TypeScript-5.0-3178C6?style=for-the-badge&logo=typescript)
![DuckDB](https://img.shields.io/badge/DuckDB-Olap-fff000?style=for-the-badge&logo=duckdb)
![FastAPI](https://img.shields.io/badge/FastAPI-High_Performance-009688?style=for-the-badge&logo=fastapi)
![Docker](https://img.shields.io/badge/Docker-Ready-2496ED?style=for-the-badge&logo=docker)
![Security](https://img.shields.io/badge/Security-Zero_Trust-critical?style=for-the-badge&logo=shield)
![License](https://img.shields.io/badge/License-MIT-green?style=for-the-badge)

> **Uma plataforma avanÃ§ada de Engenharia de Dados e InteligÃªncia Artificial para anÃ¡lise profunda do Exame Nacional do Ensino MÃ©dio (ENEM).**

O **ENEM Data Robotics V2** Ã© uma soluÃ§Ã£o "End-to-End" corporativa que combina pipelines de dados robustos, armazenamento OLAP de alta performance e um dashboard interativo moderno. O projeto visa democratizar o acesso a insights educacionais, focando em desigualdades socioeconÃ´micas, raciais e regionais com rigor estatÃ­stico.

---

## ğŸ“‹ PrÃ©-requisitos

### Requisitos de Sistema

| Recurso | MÃ­nimo | Recomendado |
|---------|--------|-------------|
| **RAM** | 8 GB | 16 GB |
| **Disco** | 100 GB livres | 150 GB livres |
| **CPU** | 4 cores | 8+ cores |

> âš ï¸ **Nota:** Os microdados do ENEM ocupam aproximadamente **70 GB** para a sÃ©rie histÃ³rica completa (1998-2024).

### Software

- **Python 3.12+** com [Poetry](https://python-poetry.org/docs/#installation)
- **Node.js 20+** com npm (para o Dashboard)
- **Docker** e **Docker Compose** (opcional, mas recomendado)

---

## ğŸ“¥ ObtenÃ§Ã£o dos Dados do INEP

Os microdados do ENEM sÃ£o pÃºblicos e disponibilizados pelo INEP. **Este repositÃ³rio NÃƒO inclui os dados** devido ao tamanho.

### 1. Download dos Microdados

Acesse o portal oficial do INEP:
- **ğŸ”— [Microdados ENEM - INEP](https://www.gov.br/inep/pt-br/acesso-a-informacao/dados-abertos/microdados/enem)**

FaÃ§a download dos arquivos `.zip` dos anos desejados.

### 2. Estrutura de DiretÃ³rios Esperada

ApÃ³s extrair os arquivos, organize-os na pasta `data/00_raw/`:

```plaintext
data/
â””â”€â”€ 00_raw/
    â”œâ”€â”€ microdados_enem_2020/
    â”‚   â””â”€â”€ DADOS/
    â”‚       â””â”€â”€ MICRODADOS_ENEM_2020.csv
    â”œâ”€â”€ microdados_enem_2021/
    â”‚   â””â”€â”€ DADOS/
    â”‚       â””â”€â”€ MICRODADOS_ENEM_2021.csv
    â”œâ”€â”€ microdados_enem_2022/
    â”‚   â””â”€â”€ DADOS/
    â”‚       â””â”€â”€ MICRODADOS_ENEM_2022.csv
    â”œâ”€â”€ microdados_enem_2023/
    â”‚   â””â”€â”€ DADOS/
    â”‚       â””â”€â”€ MICRODADOS_ENEM_2023.csv
    â””â”€â”€ microdados_enem_2024/
        â””â”€â”€ DADOS/
            â””â”€â”€ MICRODADOS_ENEM_2024.csv
```

> **Dica:** Comece com 1-2 anos recentes (2023-2024) para testes. Cada ano ocupa ~3-5 GB.

---

## ğŸš€ InstalaÃ§Ã£o e ExecuÃ§Ã£o

### OpÃ§Ã£o A: Docker (Recomendado)

A maneira mais simples de executar o projeto, garantindo todas as dependÃªncias corretas.

```bash
# 1. Clone o repositÃ³rio
git clone https://github.com/Douglas0101/Projeto_Enem_Data_Robotics_V2.git
cd Projeto_Enem_Data_Robotics_V2

# 2. Crie a estrutura de dados e adicione os microdados do INEP
mkdir -p data/00_raw

# 3. Execute com Docker Compose
docker compose up --build
```

**Acesse:**
- ğŸ“Š **Dashboard:** http://localhost:5173
- ğŸ“– **API Docs:** http://localhost:8000/docs

### OpÃ§Ã£o B: ExecuÃ§Ã£o Local (Desenvolvimento)

#### Backend (Python)

```bash
# 1. Clone o repositÃ³rio
git clone https://github.com/Douglas0101/Projeto_Enem_Data_Robotics_V2.git
cd Projeto_Enem_Data_Robotics_V2

# 2. Instale as dependÃªncias Python
poetry install

# 3. Execute o pipeline ETL (Raw â†’ Silver â†’ Gold)
poetry run enem --dashboard --anos 2023-2024

# 4. Inicie o servidor da API
poetry run enem serve
# Ou diretamente:
poetry run uvicorn enem_project.api.main:app --reload --port 8000
```

#### Frontend (React)

```bash
# Em outro terminal:
cd dashboard
npm install
npm run dev
```

**Acesse:**
- ğŸ“Š **Dashboard:** http://localhost:5173
- ğŸ“– **API Docs:** http://localhost:8000/docs

---

## âš™ï¸ Pipeline de Dados (ETL)

O projeto utiliza a **Arquitetura Medallion** (Lakehouse):

```mermaid
graph LR
    A[00_raw - CSVs INEP] -->|Raw â†’ Silver| B[01_silver - Parquet Limpo]
    B -->|Silver â†’ Gold| C[02_gold - Tabelas AnalÃ­ticas]
    C -->|DuckDB| D[API FastAPI]
    D --> E[Dashboard React]
```

### Comandos CLI

| Comando | DescriÃ§Ã£o |
|---------|-----------|
| `poetry run enem --ano 2023` | Processa Raw â†’ Silver para um ano especÃ­fico |
| `poetry run enem --anos 2020-2024` | Processa mÃºltiplos anos |
| `poetry run enem --dashboard` | Gera tabelas Gold (analÃ­ticas) para o Dashboard |
| `poetry run enem --dashboard --skip-existing` | Pula anos jÃ¡ processados |
| `poetry run enem serve` | Inicia o servidor FastAPI |

### Exemplo: Pipeline Completo

```bash
# Processa anos 2020-2024 e gera tabelas do dashboard
poetry run enem --dashboard --anos 2020-2024

# Se adicionar novos anos posteriormente:
poetry run enem --dashboard --anos 2025 --skip-existing
```

---

## ğŸ”§ VariÃ¡veis de Ambiente

| VariÃ¡vel | DescriÃ§Ã£o | PadrÃ£o |
|----------|-----------|--------|
| `ENEM_DATA_DIR` | DiretÃ³rio raiz dos dados | `./data` |
| `ENEM_FORCE_MATERIALIZE` | ForÃ§a recriaÃ§Ã£o das tabelas DuckDB | `false` |
| `DUCKDB_MEMORY_LIMIT` | Limite de memÃ³ria do DuckDB | `4GB` |
| `DUCKDB_THREADS` | Threads para processamento paralelo | `2` |
| `GEMINI_API_KEY` | Chave da API Google Gemini (IA) | - |

Crie um arquivo `.env` na raiz do projeto:

```bash
ENEM_DATA_DIR=/app/data
DUCKDB_MEMORY_LIMIT=8GB
DUCKDB_THREADS=4
GEMINI_API_KEY=sua_chave_aqui
```

---

## ğŸ“¦ Stack TecnolÃ³gica

### Backend & Data
- **Python 3.12+** / Poetry
- **FastAPI** + Pydantic v2
- **DuckDB** (OLAP embarcado)
- **Pandas** / PyArrow
- **WeasyPrint** (PDFs) / XlsxWriter (Excel)

### Frontend (Dashboard)
- **React 18** + Vite
- **TypeScript**
- **Tailwind CSS** + Radix UI
- **amCharts 5** / Recharts / D3.js

---

## ğŸ“‚ Estrutura de DiretÃ³rios

```plaintext
Projeto_Enem_Data_Robotics_V2/
â”œâ”€â”€ dashboard/              # Frontend React/Vite
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ api/            # Clientes HTTP
â”‚   â”‚   â”œâ”€â”€ components/     # UI Components + Charts
â”‚   â”‚   â””â”€â”€ pages/          # Rotas da aplicaÃ§Ã£o
â”œâ”€â”€ data/                   # Lakehouse Local (NÃƒO COMMITADO)
â”‚   â”œâ”€â”€ 00_raw/             # Microdados originais INEP
â”‚   â”œâ”€â”€ 01_silver/          # Dados limpos (Parquet)
â”‚   â””â”€â”€ 02_gold/            # Tabelas analÃ­ticas (Parquet/DuckDB)
â”œâ”€â”€ src/enem_project/       # Backend Python
â”‚   â”œâ”€â”€ api/                # Rotas FastAPI
â”‚   â”œâ”€â”€ config/             # Settings, Paths
â”‚   â”œâ”€â”€ data/               # Pipelines ETL
â”‚   â”œâ”€â”€ infra/              # DB, IO, Logging, Security
â”‚   â””â”€â”€ services/           # LÃ³gica de NegÃ³cio
â”œâ”€â”€ tests/                  # Testes unitÃ¡rios e integraÃ§Ã£o
â”œâ”€â”€ Dockerfile              # Build da API
â”œâ”€â”€ docker-compose.yml      # OrquestraÃ§Ã£o
â””â”€â”€ pyproject.toml          # DependÃªncias Python
```

---

## â— Troubleshooting

### Erro de MemÃ³ria ao Processar Anos Grandes

```bash
# Ajuste o limite de memÃ³ria do DuckDB
export DUCKDB_MEMORY_LIMIT=2GB

# Ou processe anos individualmente
poetry run enem --ano 2023
poetry run enem --ano 2024
poetry run enem --dashboard
```

### Erro: DuckDB Database Locked

O DuckDB permite apenas **uma conexÃ£o de escrita** por vez.

```bash
# Certifique-se de que o servidor da API nÃ£o estÃ¡ rodando
# ao executar pipelines ETL
pkill -f uvicorn
poetry run enem --dashboard
```

### Erro: WeasyPrint / GeraÃ§Ã£o de PDF

Instale as dependÃªncias de sistema:

```bash
# Ubuntu/Debian
sudo apt-get install libpango-1.0-0 libpangoft2-1.0-0 libcairo2 libpangocairo-1.0-0

# macOS
brew install pango cairo
```

### Docker: Network Not Found ao Reiniciar

```bash
docker compose down --remove-orphans
docker compose up --build
```

---

## ğŸ§ª Testes

```bash
# Testes unitÃ¡rios (Backend)
poetry run pytest tests/ -v

# Linting
poetry run ruff check .

# Testes de seguranÃ§a
poetry run pytest tests/test_security_engineering.py -v

# Testes E2E (Frontend)
cd dashboard
npx playwright test
```

---

## ğŸ“š DocumentaÃ§Ã£o TÃ©cnica

| Documento | DescriÃ§Ã£o |
|-----------|-----------|
| [Checklist de ProduÃ§Ã£o](Enem_documentos_e_orquestraÃ§Ã£o/checklist_producao_segura_escalavel.md) | 94 itens de seguranÃ§a e escalabilidade |
| [Plano de CiberseguranÃ§a](Enem_documentos_e_orquestraÃ§Ã£o/Ciberseguranca-e-Escalabilidade.md) | Zero Trust, IAM, proteÃ§Ã£o de dados |
| [Arquitetura do Projeto](Enem_documentos_e_orquestraÃ§Ã£o/arquitetura_projeto_enem_data_robotics.md) | Estrutura completa e orquestraÃ§Ã£o |
| [GEMINI.md](GEMINI.md) | Regras e contexto do assistente de IA |

---

## âœ¨ Destaques da VersÃ£o Atual

- **CorreÃ§Ã£o de ViÃ©s de PresenÃ§a:** Distingue inscritos vs. participantes efetivos
- **Rastreabilidade Total:** Request ID em todas as requisiÃ§Ãµes
- **PDFs Profissionais:** WeasyPrint com layout paginado
- **Zero Trust:** AutenticaÃ§Ã£o JWT + Argon2id + RBAC
- **Rate Limiting:** ProteÃ§Ã£o contra DDoS
- **Data Masking (LGPD):** ProteÃ§Ã£o de dados PII

---

## ğŸ¤ ContribuiÃ§Ã£o

1. FaÃ§a um Fork do projeto
2. Crie sua Feature Branch (`git checkout -b feature/MinhaFeature`)
3. Commit suas mudanÃ§as (`git commit -m 'Add: Minha nova feature'`)
4. Push para a Branch (`git push origin feature/MinhaFeature`)
5. Abra um Pull Request

---

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ licenciado sob a LicenÃ§a MIT - veja o arquivo [LICENSE](LICENSE) para mais detalhes.

---

<div align="center">
  <sub>Desenvolvido com ğŸ§  e â˜• por Douglas</sub>
</div>