# ğŸ¤– ENEM Data Robotics V2

![Python](https://img.shields.io/badge/Python-3.12%2B-blue?style=for-the-badge&logo=python)
![React](https://img.shields.io/badge/React-18-61DAFB?style=for-the-badge&logo=react)
![TypeScript](https://img.shields.io/badge/TypeScript-5.0-3178C6?style=for-the-badge&logo=typescript)
![DuckDB](https://img.shields.io/badge/DuckDB-Olap-fff000?style=for-the-badge&logo=duckdb)
![FastAPI](https://img.shields.io/badge/FastAPI-High_Performance-009688?style=for-the-badge&logo=fastapi)
![Docker](https://img.shields.io/badge/Docker-Ready-2496ED?style=for-the-badge&logo=docker)
![License](https://img.shields.io/badge/License-MIT-green?style=for-the-badge)

> **Uma plataforma avanÃ§ada de Engenharia de Dados e InteligÃªncia Artificial para anÃ¡lise profunda do Exame Nacional do Ensino MÃ©dio (ENEM).**

O **ENEM Data Robotics V2** Ã© uma soluÃ§Ã£o "End-to-End" corporativa que combina pipelines de dados robustos, armazenamento OLAP de alta performance e um dashboard interativo moderno. O projeto visa democratizar o acesso a insights educacionais, focando em desigualdades socioeconÃ´micas, raciais e regionais com rigor estatÃ­stico.

---

## âœ¨ Destaques da VersÃ£o Atual

### ğŸ¯ Rigor EstatÃ­stico e Qualidade de Dados
- **CorreÃ§Ã£o de ViÃ©s de PresenÃ§a:** O pipeline ETL distingue estritamente entre **Total de Inscritos** (intenÃ§Ã£o) e **Provas Aplicadas** (comparecimento efetivo). Notas de alunos ausentes sÃ£o tratadas adequadamente para garantir indicadores fiÃ©is Ã  realidade.
- **CÃ¡lculo DinÃ¢mico de Provas:** Os indicadores de desempenho consideram dinamicamente o nÃºmero de provas realizadas por cada grupo demogrÃ¡fico, garantindo precisÃ£o mesmo em casos de dados parciais.
- **MaterializaÃ§Ã£o Inteligente:** O backend SQL implementa lÃ³gica de *start-up* inteligente, evitando reprocessamentos desnecessÃ¡rios e garantindo persistÃªncia segura dos dados.

### ğŸ›¡ï¸ API e Estabilidade Profissional
- **Rastreabilidade Total:** ImplementaÃ§Ã£o de **Request ID Middleware** que adiciona identificadores Ãºnicos (`X-Request-ID`) a todas as requisiÃ§Ãµes, permitindo rastreamento preciso de logs e erros.
- **Tratamento Global de Erros:** Handler de exceÃ§Ãµes centralizado que garante que todos os erros, mesmo os inesperados (500), retornem respostas JSON estruturadas e seguras, prevenindo vazamento de stack traces.
- **Observabilidade:** Logs estruturados (JSON em produÃ§Ã£o) e instrumentaÃ§Ã£o preparada para Prometheus.

### ğŸ“‘ RelatÃ³rios Premium (Enterprise-Grade)
- **PDFs Vetoriais Profissionais:** Motor de geraÃ§Ã£o de PDF (WeasyPrint) com CSS defensivo, garantindo layout impecÃ¡vel, paginaÃ§Ã£o correta e cabeÃ§alhos repetidos em documentos multipÃ¡ginas.
- **Excel Formatado:** ExportaÃ§Ã£o de planilhas com formataÃ§Ã£o condicional, filtros e tipos de dados corretos (nÃºmeros como nÃºmeros, texto como texto) usando `xlsxwriter`.
- **SanitizaÃ§Ã£o Defensiva:** Camada de seguranÃ§a que remove caracteres de controle e formata dados numÃ©ricos antes da geraÃ§Ã£o de documentos, evitando corrupÃ§Ã£o de arquivos.

### ğŸ—ºï¸ InteligÃªncia GeogrÃ¡fica e DemogrÃ¡fica
- **EvoluÃ§Ã£o HistÃ³rica por RaÃ§a/Cor:** GrÃ¡ficos avanÃ§ados que permitem a anÃ¡lise temporal do desempenho educacional segmentado por autodeclaraÃ§Ã£o racial em cada municÃ­pio brasileiro.
- **Tooltips Contextuais Inteligentes:** VisualizaÃ§Ãµes de dados aprimoradas que exibem mÃ©dias, contagens de participantes e nÃºmero de provas contabilizadas ao interagir com os grÃ¡ficos.
- **Mapa de Calor Unificado:** VisualizaÃ§Ã£o matricial dinÃ¢mica que se ajusta automaticamente aos filtros, permitindo visÃµes macro e micro.

---

## ğŸš€ Funcionalidades Principais

### ğŸ“Š Dashboard Interativo (Frontend)
- **VisualizaÃ§Ãµes AvanÃ§adas:** GrÃ¡ficos interativos com **amCharts 5** e **Recharts**.
- **AnÃ¡lise Comparativa:** Radar charts para comparar desempenho de estados vs. mÃ©dia nacional e melhores benchmarks.
- **EvoluÃ§Ã£o HistÃ³rica:** Acompanhamento temporal de notas (2009-2024) com detalhamento por disciplinas.
- **Recortes SocioeconÃ´micos:** AnÃ¡lise detalhada de desempenho por raÃ§a, renda e localizaÃ§Ã£o geogrÃ¡fica.
- **RelatÃ³rios Profissionais:** ExportaÃ§Ã£o de dados filtrados em Excel, PDF e CSV.
- **Assistente IA:** Chat integrado para perguntas sobre os dados (Powered by Genkit).

### ğŸ› ï¸ Engenharia de Dados (Backend)
- **Arquitetura MedalhÃ£o:**
  - ğŸŸ¤ **Raw:** Dados brutos do INEP.
  - âšª **Silver:** Dados limpos, tipados e padronizados (Parquet).
  - ğŸŸ¡ **Gold:** AgregaÃ§Ãµes analÃ­ticas prontas para consumo (DuckDB + Parquet).
- **DuckDB:** Banco de dados analÃ­tico embarcado para processamento massivo local.
- **FastAPI:** API RESTful de alta performance e documentaÃ§Ã£o automÃ¡tica (Swagger UI).
- **Agentes de IA:** OrquestraÃ§Ã£o inteligente de pipelines e anÃ¡lise de dados.

---

## ğŸ—ï¸ Arquitetura do Projeto

O projeto segue uma estrutura modular e escalÃ¡vel:

```mermaid
graph TD
    A[Dados PÃºblicos INEP] -->|IngestÃ£o| B(Camada Raw)
    B -->|Limpeza & ValidaÃ§Ã£o| C(Camada Silver)
    C -->|Regras de NegÃ³cio & PresenÃ§a| D(Camada Gold - DuckDB)
    D -->|FastAPI| E[Backend Server]
    E -->|JSON/Stream| F[Dashboard React/Vite]
    G[UsuÃ¡rio] -->|Interage| F
    G -->|Query NL| H[Agente IA Genkit]
    H -->|SQL Generation| D
```

---

## ğŸ“¦ Stack TecnolÃ³gica

### Backend & Data
*   **Linguagem:** Python 3.12+
*   **Gerenciamento de DependÃªncias:** Poetry
*   **API:** FastAPI + Pydantic
*   **Banco de Dados:** DuckDB (Processamento OLAP local)
*   **Reporting Engine:** WeasyPrint (PDF), XlsxWriter (Excel)
*   **OrquestraÃ§Ã£o/IA:** Google Genkit
*   **Qualidade de Dados:** Soda Core (Validadores customizados)

### Frontend (Dashboard)
*   **Framework:** React 18 + Vite
*   **Linguagem:** TypeScript
*   **EstilizaÃ§Ã£o:** Tailwind CSS + Shadcn/UI
*   **VisualizaÃ§Ã£o de Dados:**
    *   `amcharts5`: GrÃ¡ficos complexos e mapas.
    *   `recharts`: GrÃ¡ficos estatÃ­sticos padrÃ£o.
    *   `lucide-react`: Ãcones.

---

## âš™ï¸ InstalaÃ§Ã£o e ExecuÃ§Ã£o (Docker)

A maneira recomendada de executar o projeto Ã© via Docker Compose, garantindo que todas as dependÃªncias de sistema (incluindo as necessÃ¡rias para geraÃ§Ã£o de PDF) estejam corretas.

### PrÃ©-requisitos
*   Docker Engine e Docker Compose instalados.

### Passos

1.  **Clone o repositÃ³rio:**
    ```bash
    git clone https://github.com/seu-usuario/projeto-enem-data-robotics-v2.git
    cd projeto-enem-data-robotics-v2
    ```

2.  **Execute com Docker Compose:**
    ```bash
    docker compose up --build
    ```
    Isso iniciarÃ¡ a API (Backend) e o Dashboard (Frontend).

3.  **Acesse:**
    *   **Dashboard:** [http://localhost:5173](http://localhost:5173)
    *   **DocumentaÃ§Ã£o da API:** [http://localhost:8000/docs](http://localhost:8000/docs)

### ConfiguraÃ§Ã£o de Dados
O projeto utiliza um volume local `./data` mapeado para o container. Certifique-se de que seus dados brutos ou processados estejam na pasta `data/` local para persistÃªncia.

---

## ğŸ“‚ Estrutura de DiretÃ³rios

```plaintext
Projeto_Enem_Data_Robotics_V2/
â”œâ”€â”€ config/                 # ConfiguraÃ§Ãµes de hardware e ambiente
â”œâ”€â”€ dashboard/              # AplicaÃ§Ã£o Frontend (React/Vite)
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ api/            # Clientes HTTP (Axios)
â”‚   â”‚   â”œâ”€â”€ components/     # Componentes UI (Charts, Maps, PremiumReport)
â”‚   â”‚   â”œâ”€â”€ pages/          # Rotas da aplicaÃ§Ã£o
â”‚   â”‚   â””â”€â”€ ...
â”œâ”€â”€ data/                   # Lakehouse Local (Mapeado no Docker)
â”‚   â”œâ”€â”€ 00_raw/             # Dados brutos
â”‚   â”œâ”€â”€ 01_silver/          # Dados limpos (Parquet)
â”‚   â””â”€â”€ 02_gold/            # Dados agregados (Parquet)
â”œâ”€â”€ Enem_documentos_e_orquestraÃ§Ã£o/ # DocumentaÃ§Ã£o Arquitetural e AgÃªntica
â”œâ”€â”€ src/                    # CÃ³digo Fonte Backend
â”‚   â””â”€â”€ enem_project/
â”‚       â”œâ”€â”€ api/            # Rotas FastAPI e LÃ³gica de Endpoints
â”‚       â”œâ”€â”€ data/           # Pipelines ETL (Raw->Silver->Gold)
â”‚       â”œâ”€â”€ infra/          # ConexÃ£o DB, Logging, IO
â”‚       â”œâ”€â”€ services/       # ServiÃ§os de DomÃ­nio (ReportService, etc.)
â”‚       â””â”€â”€ orchestrator/   # Agentes e Workflows
â”œâ”€â”€ tests/                  # Testes unitÃ¡rios e de integraÃ§Ã£o
â”œâ”€â”€ .genkit/                # ConfiguraÃ§Ã£o do Genkit (IA)
â”œâ”€â”€ Dockerfile              # DefiniÃ§Ã£o da imagem da API
â”œâ”€â”€ docker-compose.yml      # OrquestraÃ§Ã£o dos serviÃ§os
â”œâ”€â”€ GEMINI.md               # Regras e Contexto do Assistente
â””â”€â”€ README.md               # DocumentaÃ§Ã£o do Projeto
```

---

## ğŸ§ª Testes e Qualidade

Para garantir a integridade dos dados e do cÃ³digo (executando localmente):

```bash
# Instalar dependÃªncias de desenvolvimento
poetry install

# Executar testes unitÃ¡rios (Backend)
poetry run pytest tests/

# Executar linter
poetry run ruff check .
```

---

## ğŸ¤ ContribuiÃ§Ã£o

ContribuiÃ§Ãµes sÃ£o bem-vindas! Sinta-se Ã  vontade para abrir **Issues** para reportar bugs ou **Pull Requests** para melhorias.

1.  FaÃ§a um Fork do projeto
2.  Crie sua Feature Branch (`git checkout -b feature/MinhaFeature`)
3.  Commit suas mudanÃ§as (`git commit -m 'Add: Minha nova feature'`)
4.  Push para a Branch (`git push origin feature/MinhaFeature`)
5.  Abra um Pull Request

---

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ licenciado sob a LicenÃ§a MIT - veja o arquivo [LICENSE](LICENSE) para mais detalhes.

---

<div align="center">
  <sub>Desenvolvido com ğŸ§  e â˜• por Douglas</sub>
</div>